{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "This notebook contains solutions for the [week 1 assignments](https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/week_1_basics_n_setup)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1. Knowing docker tags**\n",
    "\n",
    "Run the command to get information on Docker: `docker --help`. Now run the command to get help on the `docker build` command - which tag has the following text: *Write the image ID to the file*?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      --iidfile string          Write the image ID to the file\n"
     ]
    }
   ],
   "source": [
    "!docker build --help | grep \"Write the image ID to the file\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2. Understanding docker first run**\n",
    "\n",
    "Run docker with the *python:3.9* image in an interactive mode and the entrypoint of bash. Now check the python modules that are installed (use `pip list`). How many python packages/modules are installed?\n",
    "\n",
    "Answer (commands you need to run in order):\n",
    "\n",
    "    docker run -it --entrypoint=bash python:3.9\n",
    "\n",
    "    <After container has been run, you will be in able to execute commands inside the container using bash. Your bash prompt should look something like this: root@92ffd1826989:/#>\n",
    "    \n",
    "    pip list\n",
    "    Package    Version\n",
    "    ---------- -------\n",
    "    pip        22.0.4\n",
    "    setuptools 58.1.0\n",
    "    wheel      0.38.4\n",
    "    WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
    "    You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Database Setup**\n",
    "\n",
    "Before proceeding with the tasks, we need to do some preparation. \n",
    "\n",
    "Firstly, we need to run a local instance of PostgreSQL - I have created a basic setup using Docker Compose [here](\"./docker-compose.yaml\"). This setup uses [pgAdmin](https://www.pgadmin.org/) for convinience reasons, although it is not necessary - we might as well interact with the database using other tools, like [pgcli](https://www.pgcli.com/) or simply *pandas* library.\n",
    "\n",
    "Secondly, we need to ingest some data to that database - the data we will be using is [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page). Before May 2022, that data was stored in CSV files, which DataTalksClub backed up and made available [here](https://github.com/DataTalksClub/nyc-tlc-data). As I found some minor discrepancies between the backup CSV files and the \"current\" Parquet files, I'd recommend using the former to make sure the output of your queries will be consistent with the answers to the questions.\n",
    "\n",
    "To ingest the data, we need to create tables with the appropriate schema inside our database. Although for this week we are only using Green Taxi Trip Records from Jan 2021 and Taxi Zone Lookup Table, we will create tables for each \"type\" of trips (except High Volume For-Hire Vehicle Trip Records, as the backup for those is incomplete as of now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_data = pd.read_csv(\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2019-01.csv.gz\", nrows=100)\n",
    "green_data = pd.read_csv(\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz\", nrows=100)\n",
    "fhv_data = pd.read_csv(\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-01.csv.gz\", nrows=100)\n",
    "\n",
    "# We are gonna load the entire Taxi Zone Lookup Table as we only have to ingest it once\n",
    "zone_data = pd.read_csv(\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some basic data cleanup, namely converting the appropriate columns in the datasets to *datetime* type (note, if you are working with Parquet files, you will not have this problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_data[\"tpep_pickup_datetime\"] = pd.to_datetime(yellow_data[\"tpep_pickup_datetime\"])\n",
    "yellow_data[\"tpep_dropoff_datetime\"] = pd.to_datetime(yellow_data[\"tpep_dropoff_datetime\"])\n",
    "\n",
    "green_data[\"lpep_pickup_datetime\"] = pd.to_datetime(green_data[\"lpep_pickup_datetime\"])\n",
    "green_data[\"lpep_dropoff_datetime\"] = pd.to_datetime(green_data[\"lpep_dropoff_datetime\"])\n",
    "\n",
    "fhv_data[\"pickup_datetime\"] = pd.to_datetime(fhv_data[\"pickup_datetime\"])\n",
    "fhv_data[\"dropOff_datetime\"] = pd.to_datetime(fhv_data[\"dropOff_datetime\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the schema from the `pandas.DataFrame` and generate the DDL statement compatibile with Postgres, we need an appropriate *SQLAlchemy Engine*. Note that the URL you will pass to the `create_engine` function depends on the configuration you have specified in the *docker-compose* file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql://root:root@localhost:54320/nyc_tlc_trips\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we successfully established connection to the database, we can start creating tables and ingesting the data. For now, we are gonna ingest the entire Taxi Zone Lookup data and only create tables for the remaining datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingesting Taxi Zone Lookup table\n",
    "zone_data.to_sql(\n",
    "    name=\"taxi_zone\", con=engine, if_exists=\"replace\", index=False\n",
    ")\n",
    "\n",
    "# Creating tables for Yellow Taxi Trips, Green Taxi Trips and For-Hire Vehicles Trips\n",
    "yellow_data.to_sql(\n",
    "    name=\"yellow_taxi_trip\", con=engine, if_exists=\"replace\", index=False\n",
    ")\n",
    "green_data.to_sql(\n",
    "    name=\"green_taxi_trip\", con=engine, if_exists=\"replace\", index=False\n",
    ")\n",
    "fhv_data.to_sql(name=\"fhv_trip\", con=engine, if_exists=\"replace\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see what kind of DDL was used to create the tables, you can see the exact queries through pgAdmin. You can also examine the data types assigned to your columns using pandas (note, that this is not the **exact** query that was used to create the table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE taxi_zone (\n",
      "\t\"LocationID\" BIGINT, \n",
      "\t\"Borough\" TEXT, \n",
      "\t\"Zone\" TEXT, \n",
      "\tservice_zone TEXT\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(zone_data, con=engine, name=\"taxi_zone\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE ABOUT INGESTING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_airflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfbc7bbf1c7436e7ffe090bb5db41c3cddd847fd68379666776530bf84f447e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
